{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis (pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This series of lessons will focus on [pandas](https://pandas.pydata.org/pandas-docs/stable/getting_started/overview.html), a powerful Python library for working with tabular data like CSV files.\n",
    "\n",
    "This incredible workbook is authored by [Melanie Walsh](https://melaniewalsh.org/) (with minor modifications) and is available as part of her open-source book [Introduction to Cultural Analytics & Python](https://melaniewalsh.github.io/Intro-Cultural-Analytics/welcome.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file is an example of a Jupyter Notebook. A Jupyter notebook is a document that can combine live programming code, text (formatted using something called Markdown), images, and pretty displays of data all in the same place. This combination makes Jupyter notebooks useful for exploring data as well as for learning and teaching.\n",
    "\n",
    "A Jupyter notebook has a special .ipynb file extension and can only be opened if you have the application JupyterLab or Jupyter Notebook installed and running, or on a cloud server like Binder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pandas basics — Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: You can explore the [associated workbook](https://mybinder.org/v2/gh/melaniewalsh/Intro-Cultural-Analytics/master?urlpath=lab/tree/book/03-Data-Analysis/workbooks/01.5-Pandas-Basics-Part1-WORKBOOK.ipynb) for this chapter in the cloud.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we're going to introduce some of the basics of [pandas](https://pandas.pydata.org/pandas-docs/stable/getting_started/overview.html), a powerful Python library for working with tabular data like CSV files.  A CSV file is like an Excel file, basically with column headings and rows of data.\n",
    "\n",
    "We will cover how to:\n",
    "\n",
    "* import pandas\n",
    "* Read in a CSV file\n",
    "* Explore and filter data\n",
    "* Make simple plots and data visualizations\n",
    "* Write to a CSV file\n",
    "\n",
    "___\n",
    "\n",
    "## Dataset\n",
    "### The Bellevue Almshouse Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote class=\"epigraph\" style=\" padding: 10px\">\n",
    "\n",
    "Nineteenth-century immigration data was produced with the express purpose of reducing people to bodies; bodies to easily quantifiable aspects; and assigning value to those aspects which proved that the marginalized people to who they belonged were worth less than their elite counterparts.\n",
    "\n",
    "-Anelise Shrout, [\"(Re)Humanizing Data\"](https://crdh.rrchnm.org/essays/v01-10-(re)-humanizing-data/)\n",
    "</blockquote>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset that we're working with in this lesson is the [Bellevue Almshouse Dataset](https://www.nyuirish.net/almshouse/the-almshouse-records/), created by historian and DH scholar Anelise Shrout. It includes information about Irish-born immigrants who were admitted to New York City's Bellevue Almshouse in the 1840s.\n",
    "\n",
    "The Bellevue Almshouse was part of New York City's public health system, a place where poor, sick, homeless, and otherwise marginalized people were sent — sometimes voluntarily and sometimes forcibly. Devastated by widespread famine in Ireland, many Irish people fled their homes for New York City in the 1840s, and many of them ended up in the Bellevue Almshouse.\n",
    "\n",
    "We're using the [Bellevue Almshouse Dataset](https://www.nyuirish.net/almshouse/the-almshouse-records/) to practice data analysis with Pandas because we want to think deeply about the consequences of reducing human life to data. As Shrout argues in [her essay](https://crdh.rrchnm.org/essays/v01-10-(re)-humanizing-data/), this data purposely reduced people to bodies and \"easily quantifiable aspects\" in order to devalue their lives, potentially enacting \"both epistemic and physical violence\" on them.\n",
    "\n",
    "We want to think about how responsible data analysis requires more than just technical tools like Pandas. It also requires an interrogation of the data. Who collected this data? How and why was this data collected? What assumptions are present in this data? What are the consequences of this data in the world? What does this data reflect about the world? For example, Shrout claims that the \"Bellevue administrators framed any ailments or difficulties inmates might have had as a consequence of [their immigration] status\" — perhaps best exemplified by the fact that a frequent \"disease\" in the dataset is \"recent emigrant.\" Below we're going to explore the prevalence of \"recent emigrant\" in the data as well as other salient patterns.\n",
    "\n",
    "___\n",
    "\n",
    "## Import pandas\n",
    "\n",
    "To use the Pandas library, we first need to `import` it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above `import` statement not only imports the `pandas` library but also gives it an alias or nickname — `pd`. This alias will save us from having to type out the entire words `pandas` each time we need to use it. Many Python libraries have commonly used aliases like `pd`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Display Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, `pandas` will display 60 rows and 20 columns. I often change [pandas' default display settings](https://pandas.pydata.org/pandas-docs/stable/user_guide/options.html) to show more rows or columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in CSV File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read in a CSV file, we will use the function `pd.read_csv()` and insert the name of our desired file path. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellevue_df = pd.read_csv('bellevue_almshouse_dataset.csv', delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a pandas [DataFrame object](https://pandas.pydata.org/pandas-docs/stable/user_guide/dsintro.html#dataframe) — often abbreviated as **df**, e.g., **bellevue_df**. A DataFrame looks and acts a lot like a spreadsheet. But it has special powers and functions that we will discuss in the next few lessons.\n",
    "\n",
    "When reading in the CSV file, we also specified the `encoding` and `delimiter`. The `delimiter` specifies the character that separates or \"delimits\" the columns in our dataset. For CSV files, the delimiter will most often be a comma. (CSV is short for *Comma Separated Values*.) Sometimes, however, the delimiter of a CSV file might be a tab (`\\t`) or, more rarely, another character.\n",
    "\n",
    "## Display Data\n",
    "\n",
    "We can display a DataFrame in a Jupyter notebook simply by running a cell with the variable name of the DataFrame. When a code cell ends with a variable name, it is the same as printing the contents of that variable.\n",
    "\n",
    ":::<code>NaN</code> is the `pandas` value for any missing data. See <a href=\"https://pandas.pydata.org/pandas-docs/stable/user_guide/missing_data.html?highlight=nan/\">\"Working with missing data\"</a> for more information.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellevue_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few important things to note about the DataFrame displayed here:\n",
    "\n",
    "* Index\n",
    "    * The bolded ascending numbers in the very left-hand column of the DataFrame is called the pandas *Index*. You can select rows based on the Index.\n",
    "    * By default, the Index is a sequence of numbers starting with zero. However, you can change the Index to something else, such as one of the columns in your dataset.\n",
    "\n",
    "* Truncation\n",
    "    * The DataFrame is truncated, signaled by the ellipses in the middle `...` of every column.\n",
    "    * The DataFrame is truncated because we set our default display settings to 100 rows. Anything more than 100 rows will be truncated. To display all the rows, we would need to alter pandas' default display settings yet again.\n",
    "\n",
    "* Rows x Columns\n",
    "    * Pandas reports how many rows and columns are in this dataset at the bottom of the output (9584 x 8 columns).\n",
    "    * This is very useful!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display First *n* Rows\n",
    "\n",
    "To look at the first *n* rows in a DataFrame, we can use a method called `.head()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellevue_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellevue_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "Play around with the code! What happens if you try to invoke `head` with no parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Random Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To look at a random sample of rows, we can use the `.sample()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellevue_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get important info about all the columns in the DataFrame, we can use `.info()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellevue_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This report will tell us how many non-null, or non-blank, values are in each column, as well as what *type* of data is in each column.\n",
    "\n",
    "\n",
    "\n",
    "| **Pandas Data Type** |  **Explanation**                                                                                   |\n",
    "|:-------------:|:---------------------------------------------------------------------------------------------------:|\n",
    "| `object`         | string                                                                               |\n",
    "| `float64`         | float                                               |\n",
    "| `int64`       | integer                                                        |\n",
    "| `datetime64`       |  date time              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Summary Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate summary statistics for every column in our DataFrame, we can use the `.describe()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellevue_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To round values to any number of decimal places, we can use the `.round()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellevue_df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, `.describe()` will only compute columns with numerical data. To include all columns, we can use `include='all`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellevue_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some insights that can be gleaned from these summary statistics:\n",
    "- We cannot compute numerical statistics for columns that are not numeric. `NaN` indicates \"not a number\"\n",
    "- For the column **first_name**, the most frequently occurring first name (**top**) is Mary, which appears 979 times (**freq**)\n",
    "- For the column **last_name**, the most frequently occurring last name (**top**) is Kelly, which appears 137 times (**freq**)\n",
    "- For the column **age**, average age in the dataset (**mean**) is 30, the youngest (**min**) is .08, and the oldest (**max**) is 97\n",
    "- For the columns **disease** and **profession**, there are 75 unique (**unique**) diseases and 172 unique (**unique**) professions\n",
    "- For the column **children**, there are 37 rows that include information about children (**count**) (i.e., rows that do not have blank values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To select a column from the DataFrame, we will type the name of the DataFrame followed by square brackets and a column name in quotations marks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellevue_df['disease']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Technically, a single column in a DataFrame is a [*Series* object](https://pandas.pydata.org/pandas-docs/stable/user_guide/dsintro.html#dsintro)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(bellevue_df['disease'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Series object displays differently than a DataFrame object. To select a column as a DataFrame and not as a Series object, we will use two square brackets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellevue_df[['disease']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(bellevue_df[['disease']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using two square brackets, we can also select multiple columns at the same time. This allows us to make a smaller DataFrame from a big one by only selecting the columns that we need. This is useful when a dataset contains a lot of data that we don't need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellevue_df[['first_name', 'last_name', 'disease']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` {warning}\n",
    "Heads up! The code below will cause an error. This will cause all the cell clock below to not run until you specify that they should.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See what happens if we try to select multiple columns as a Series..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "bellevue_df['first_name', 'last_name', 'disease']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To count the number of *unique* values in a column, we can use the `.value_counts()` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{sidebar} On Bellevue Almshouse \"Diseases\"\n",
    "> Some were diagnosed with medically recognizable illnesses, including “fever,” “dropsy” and “neuralgia.” Others were diagnosed with “diseases” that made visible the ways in which immigrants were failing to meet the expectations of urban citizenship. These included “destitution” and “recent emigrant.” Neither of these diagnoses reflected an immigrant’s health. Nevertheless, they were treated as pathologies, and those pathologies governed city officials perceptions of immigrants. Sickness, injuries or destitution were subsumed under the pathology of “recent emigrant.” This diagnosis also determined immigrants’ paths through the New York City public health system.\n",
    "\n",
    "-Anelise Shrout, [\"(Re)Humanizing Data: Digitally Navigating the Bellevue Almshouse\"](https://crdh.rrchnm.org/essays/v01-10-(re)-humanizing-data/)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bellevue_df['disease'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look through the so-called \"diseases\" recorded in the Bellevue Almshouse data and consider what these categories reflect about New York City in the 1840s, particularly with regard to immigration status."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To select the top 10 most frequent values in the \"disease\" column, we can combine `value_counts()` with regular Python list slicing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellevue_df['disease'].value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellevue_df['profession'].value_counts()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a similar vein, consider what these \"professions\" reflect about New York City in the 1840s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "What were the top 5 first names, top 5 last names, top 10 first and last names pairings?\n",
    "Write your code in the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 5 first names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 5 last names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 10 first name, last name pairings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make and Save Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pandas` makes it easy to create plots and data visualizations. We can make a simple plot by adding `.plot()` to any DataFrame or Series object that has appropriate numeric data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellevue_df['disease'].value_counts()[:10].plot(kind='bar', title='Bellevue Almshouse:\\nMost Frequent \"Diseases\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We specify the title with the `title=` parameter and the kind of plot by altering the `kind=` parameter:\n",
    "* ‘bar’ or ‘barh’ for bar plots\n",
    "\n",
    "* ‘hist’ for histogram\n",
    "\n",
    "* ‘box’ for boxplot\n",
    "\n",
    "* ‘kde’ or ‘density’ for density plots\n",
    "\n",
    "* ‘area’ for area plots\n",
    "\n",
    "* ‘scatter’ for scatter plots\n",
    "\n",
    "* ‘hexbin’ for hexagonal bin plots\n",
    "\n",
    "* ‘pie’ for pie plots\n",
    "\n",
    "* ‘line’ for line plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, to make a horizontal bar chart, we can set `kind='barh'`Note that due to calling `.get_figure().savefig(Bellevue)`, the file `Bellevue.png` will be saved in our folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellevue_df['disease'].value_counts()[:10].plot(kind='barh',title='Bellevue Almshouse:\\nMost Frequent \"Diseases\"').get_figure().savefig('Bellevue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make a pie chart, we can set `kind='pie'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellevue_df['profession'].value_counts()[:10].plot(kind='pie', figsize=(10, 10), title='Bellevue Almshouse:\\nMost Frequent \"Professions\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's make a histogram plot of the age of the people in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellevue_df.plot.hist(y='age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing the appropriate chart\n",
    "\n",
    "![Graphing recommendations](graphing_recs.png)\n",
    "\n",
    "Source: [Scientific computing 2017](https://github.com/nerdcommander/scientific_computing_2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save a plot as an image file or PDF file, we can assign the plot to a variable called `ax`, short for axes.\n",
    "\n",
    "Then we can use `ax.figure.savefig('FILE-NAME.png')` or `ax.figure.savefig('FILE-NAME.pdf')`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = bellevue_df['profession'].value_counts()[:10].plot(kind='pie', figsize=(10, 10), title='Bellevue Almshouse:\\nMost Frequent \"Professions\"')\n",
    "ax.figure.savefig('Bellevue-professions_pie-chart.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your plot is being cut off in the image, see Pandas Basics Part 2 (\"Prevent Labels From Getting Cut Off\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter/Subset Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can filter a Pandas DataFrame to select only certain values. Filtering data by certain values is similar to selecting columns.\n",
    "\n",
    "We type the name of the DataFrame followed by square brackets and then, instead of inserting a column name, we insert a True/False condition. For example, to select only rows that contain the value \"teacher,\" we insert the condition `bellevue_df['profession'] == 'teacher'`. Notice that this condition is compairing a Series (or column) to a string. This is part of the magic of `pandas`: it will take care of iterating through the Series and selecting only the rows where the condition is True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellevue_df[bellevue_df['profession'] == 'teacher']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be helpful to isolate this condition and see that it produces a long list of True/False pairs for every row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellevue_df['profession'] == 'teacher'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering DataFrames can sometimes get confusing and unwieldy (as conditions within conditions pile up like Russian Matryoshka Dolls). It can be helpful to make a separate variable for a filter, as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_filter = bellevue_df['profession'] == 'teacher'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellevue_df[teacher_filter]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a similar vein, it's often useful to make a new variable for a filtered DataFrame. For example, let's say we wanted to look at only the women in the dataset and see the most commons professions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "women_filter = bellevue_df['gender'] == 'f'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the results of DataFrame obtained by women_filter in bellevue_women\n",
    "bellevue_women = bellevue_df[women_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the professions of women only\n",
    "bellevue_women['profession'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the top 3 professions of women as a pie chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a lot we can do with filters beyond exact value matches with an equals operator `==`.\n",
    "\n",
    "We can also incorporate `>`, `<`, `>=`, `<=` with integers, floats, and even dates. For example, we can filter the DataFrame for only people who arrived to the Bellevue Almshouse on or after '1847-04-17'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_filter = bellevue_df['date_in'] >= '1847-04-17'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bellevue_df[date_filter]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To output a new CSV file, we can use the `.to_csv` method with a name for the file in quotation marks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how we might output a new CSV file that only includes rows with women.  This will create the `Bellevue_women.csv` file in our folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellevue_women.to_csv(\"Bellevue_women.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to a filename, we're also specifying that the encoding is utf-8 and that the Index (the bolded left-most column) is not included in the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellevue_women"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [10 minutes to Pandas](https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html), Pandas Official Documentation\n",
    "- [\"Data Manipulation with Pandas\"](https://jakevdp.github.io/PythonDataScienceHandbook/03.00-introduction-to-pandas.html), *Python Data Science*, Jake VanderPlas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
